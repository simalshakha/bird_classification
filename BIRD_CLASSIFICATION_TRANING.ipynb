{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_func = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_datasets = datasets.ImageFolder(\n",
    "    'PetImages/train',\n",
    "    transform=transforms_func\n",
    ")\n",
    "val_datasets = datasets.ImageFolder(\n",
    "    'PetImages/val',\n",
    "    transform=transforms_func\n",
    ")\n",
    "test_datasets = datasets.ImageFolder(\n",
    "    'PetImages/test',\n",
    "    transform=transforms_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_datasets, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_datasets, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "        self.features_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # self.fc1 = nn.Linear(9216, 4096)\n",
    "        # self.fc2 = nn.Linear(4096, 4096)\n",
    "        # self.fc3 = nn.Linear(4096, 1)\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=1),\n",
    "\n",
    "            nn.Linear(4096, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == 3, 227, 227\n",
    "        x = self.features_extractor(x)\n",
    "        x = self.fcn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline / Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          criteria, \n",
    "          optimizer, \n",
    "          train_dataloader, \n",
    "          val_dataloader, \n",
    "          epochs, \n",
    "          device, \n",
    "          val_iteration=1,\n",
    "          ):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        ## Train \n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        train_step = 0\n",
    "        for batch_images, batch_labels in tqdm(train_dataloader):\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            results = model(batch_images)\n",
    "            loss = criteria(results, batch_labels.unsqueeze(1).float())\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward() # calcuate gradients\n",
    "            optimizer.step() # update weights using gradients\n",
    "            train_step += 1\n",
    "            epoch_train_loss += loss.item()\n",
    "        epoch_train_loss /= train_step\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        print(f\"Epoch {epoch} of {epochs}: train loss = {epoch_train_loss:.4f}\")\n",
    "\n",
    "        ## Validation \n",
    "        if epoch % val_iteration == 0:\n",
    "            model.eval()\n",
    "\n",
    "            epoch_val_loss = 0\n",
    "            val_step = 0\n",
    "\n",
    "            epoch_val_correct = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_images, batch_labels in val_dataloader:\n",
    "                    batch_images = batch_images.to(device)\n",
    "                    batch_labels = batch_labels.to(device)\n",
    "                    \n",
    "                    # Validation only have forward pass no backward pass \n",
    "                    # forward pass \n",
    "                    \n",
    "\n",
    "                    results = model(batch_images)\n",
    "                    loss = criteria(results, batch_labels.unsqueeze(1).float())\n",
    "                    epoch_val_loss += loss.item()\n",
    "                    val_step += 1\n",
    "                    epoch_val_correct += (results.round() == batch_labels.unsqueeze(1)).type(torch.float).sum().item()\n",
    "\n",
    "            epoch_val_loss /= val_step\n",
    "            val_loss.append(epoch_val_loss)\n",
    "            epoch_val_accuracy = epoch_val_correct / len(val_dataloader.dataset)\n",
    "            val_accuracy.append(epoch_val_accuracy)\n",
    "            print(f\"Epoch {epoch} of {epochs}: validation loss = {epoch_val_loss:.4f}\")\n",
    "            print(f\"Epoch {epoch} of {epochs}: validation Accu = {epoch_val_accuracy:.4f}\")\n",
    "    return train_loss, val_loss, val_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 \n",
    "\n",
    "alexnet = AlexNet().to(device)\n",
    "criteria = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 210/1094 [00:46<03:13,  4.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss, val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43malexnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criteria, optimizer, train_dataloader, val_dataloader, epochs, device, val_iteration)\u001b[0m\n\u001b[0;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update weights using gradients\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     train_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 32\u001b[0m     epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m epoch_train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m train_step\n\u001b[0;32m     34\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(epoch_train_loss)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, val_loss, val_accuracy = train(alexnet, criteria, optimizer, train_dataloader, val_dataloader, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
